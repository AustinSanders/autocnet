{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Disabled\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "import uuid\n",
    "\n",
    "from autocnet.examples import get_path\n",
    "from autocnet.graph.network import CandidateGraph, Node, Edge\n",
    "from autocnet.graph.edge import Edge\n",
    "from autocnet.matcher.feature import FlannMatcher\n",
    "\n",
    "from plio.io import io_autocnetgraph\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import farmhash\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a 2 image adjacenecy graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jlaura/github/autocnet/autocnet/transformation/fundamental_matrix.py:193: UserWarning: Unable to apply MLE.  Not enough correspondences.  Returning with a RANSAC computed F matrix.\n",
      "  warnings.warn(\"Unable to apply MLE.  Not enough correspondences.  Returning with a RANSAC computed F matrix.\")\n"
     ]
    }
   ],
   "source": [
    "#Point to the adjacency Graph\n",
    "adjacency = get_path('three_image_adjacency.json')\n",
    "basepath = get_path('Apollo15')\n",
    "cg = CandidateGraph.from_adjacency(adjacency, basepath=basepath)\n",
    "\n",
    "#Apply SIFT to extract features\n",
    "cg.extract_features(method='sift', extractor_parameters={'nfeatures':50})\n",
    "\n",
    "#Match\n",
    "cg.match()\n",
    "\n",
    "#Apply outlier detection\n",
    "cg.symmetry_checks()\n",
    "cg.ratio_checks()\n",
    "cg.compute_fundamental_matrices()\n",
    "cg.compute_homographies()\n",
    "cg.save('example_save.project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from plio.io.io_autocnetgraph import load\n",
    "rebuilt = load('example_save.project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg == rebuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "\n",
    "from networkx.readwrite import json_graph\n",
    "import base64\n",
    "import json\n",
    "import h5py\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        \"\"\"If input object is an ndarray it will be converted into a dict \n",
    "        holding dtype, shape and the data, base64 encoded.\n",
    "        \"\"\"\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return dict(__ndarray__= obj.tolist(),\n",
    "                        dtype=str(obj.dtype),\n",
    "                        shape=obj.shape)\n",
    "        elif isinstance(obj, uuid.UUID):\n",
    "            return obj.hex\n",
    "        # Let the base class default method raise the TypeError\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "def save(network, projectname):\n",
    "    \"\"\"\n",
    "    Save an AutoCNet candiate graph to disk in a compressed file.  The\n",
    "    graph adjacency structure is stored as human readable JSON and all\n",
    "    potentially large numpy arrays are stored as compressed binary. The\n",
    "    project archive is a standard .zip file that can have any ending,\n",
    "    e.g., <projectname>.project, <projectname>.zip, <projectname>.myname.\n",
    "    \n",
    "    TODO: This func. writes a intermediary .npz to disk when saving.  Can\n",
    "    we write the .npz to memory?\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    network : object\n",
    "              The AutoCNet Candidate Graph object\n",
    "    \n",
    "    projectname : str\n",
    "                  The PATH to the output file.\n",
    "    \"\"\"\n",
    "    # Convert the graph into json format\n",
    "    js = json_graph.node_link_data(network) \n",
    "    \n",
    "    with ZipFile(projectname, 'w') as pzip:\n",
    "        js_str = json.dumps(js, cls=NumpyEncoder, sort_keys=True, indent=4)\n",
    "        pzip.writestr('graph.json', js_str)\n",
    "\n",
    "        # Write the array node_attributes to hdf\n",
    "        for n, data in network.nodes_iter(data=True):\n",
    "            grp = data['node_id']\n",
    "            np.savez('{}.npz'.format(data['node_id']),\n",
    "                     descriptors=data.descriptors,\n",
    "                     _keypoints=data._keypoints,\n",
    "                     _keypoints_idx=data._keypoints.index,\n",
    "                     _keypoints_columns=data._keypoints.columns)\n",
    "            pzip.write('{}.npz'.format(data['node_id']))\n",
    "            os.remove('{}.npz'.format(data['node_id']))\n",
    "\n",
    "        # Write the array edge attributes to hdf\n",
    "        for s, d, data in network.edges_iter(data=True):\n",
    "            if s > d:\n",
    "                s, d = d, s\n",
    "            grp = str((s,d))\n",
    "            np.savez('{}_{}.npz'.format(s, d),\n",
    "                     matches=data.matches,\n",
    "                     matches_idx=data.matches.index,\n",
    "                     matches_columns=data.matches.columns,\n",
    "                     _masks=data._masks,\n",
    "                     _masks_idx=data._masks.index,\n",
    "                     _masks_columns=data._masks.columns)\n",
    "            pzip.write('{}_{}.npz'.format(s, d))\n",
    "            os.remove('{}_{}.npz'.format(s, d))\n",
    "save(cg, 'sampleout.project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 7232\r\n",
      "drwxr-xr-x  16 jlaura  flagstaf   544B Feb  2 09:52 \u001b[34m.\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  37 jlaura  flagstaf   1.2K Feb  2 09:14 \u001b[34m..\u001b[m\u001b[m\r\n",
      "-rw-r--r--@  1 jlaura  flagstaf   8.0K Feb  2 09:29 .DS_Store\r\n",
      "drwxr-xr-x   9 jlaura  flagstaf   306B Jan 11 19:53 \u001b[34m.ipynb_checkpoints\u001b[m\u001b[m\r\n",
      "-rw-r--r--   1 jlaura  flagstaf   4.9K Jan 11 19:48 Ciratefi.ipynb\r\n",
      "-rw-r--r--   1 jlaura  flagstaf   1.3M Dec 16 20:55 Coupled+Decomposition.ipynb\r\n",
      "-rw-r--r--   1 jlaura  flagstaf    13K Dec  3 13:14 ISIS Serial Numbers.ipynb\r\n",
      "-rw-r--r--   1 jlaura  flagstaf    26K Feb  2 09:52 Saving.ipynb\r\n",
      "-rw-r--r--   1 jlaura  flagstaf   7.1K Jan 11 19:48 Suppression vis Disk Covering.ipynb\r\n",
      "-rw-r--r--   1 jlaura  flagstaf   9.7K Jan 31 07:41 Testing Cuda Integration.ipynb\r\n",
      "-rw-r--r--   1 jlaura  flagstaf    24K Dec  3 13:14 Testing Slopes.ipynb\r\n",
      "-rw-r--r--   1 jlaura  flagstaf   1.4M Jan 11 19:48 Tutorial with Visualization.ipynb\r\n",
      "-rw-r--r--   1 jlaura  flagstaf   453K Jan 11 19:49 Voronoi.ipynb\r\n",
      "drwx------   9 jlaura  flagstaf   306B Feb  2 09:29 \u001b[34msampleout\u001b[m\u001b[m\r\n",
      "-rw-r--r--   1 jlaura  flagstaf   118K Feb  2 09:52 sampleout.project\r\n",
      "-rw-r--r--@  1 jlaura  flagstaf   118K Feb  2 09:28 sampleout.project.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls -alh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def json_numpy_obj_hook(dct):\n",
    "    \"\"\"Decodes a previously encoded numpy ndarray with proper shape and dtype.\n",
    "\n",
    "    :param dct: (dict) json encoded ndarray\n",
    "    :return: (ndarray) if input was an encoded ndarray\n",
    "    \"\"\"\n",
    "    if isinstance(dct, dict) and '__ndarray__' in dct:\n",
    "        data = np.asarray(dct['__ndarray__'])\n",
    "        return np.frombuffer(data, dct['dtype']).reshape(dct['shape'])\n",
    "    return dct\n",
    "\n",
    "def load(projectname):\n",
    "    with ZipFile(projectname, 'r') as pzip:\n",
    "        # Read the graph object\n",
    "        with pzip.open('graph.json', 'r') as g:\n",
    "            data = json.loads(g.read().decode(),object_hook=json_numpy_obj_hook)\n",
    "        \n",
    "        cg = CandidateGraph()\n",
    "        # Reload the graph attributes\n",
    "        cg.graph = data['graph']\n",
    "        # Handle nodes\n",
    "        for d in data['nodes']:\n",
    "            n = Node(image_name=d['image_name'], image_path=d['image_path'], node_id=d['id'])\n",
    "            n['hash'] = d['hash']\n",
    "            # Load the byte stream for the nested npz file into memory and then unpack\n",
    "            nzf = np.load(BytesIO(pzip.read('{}.npz'.format(d['id']))))\n",
    "            n._keypoints = pd.DataFrame(nzf['_keypoints'], index=nzf['_keypoints_idx'], columns=nzf['_keypoints_columns'])\n",
    "            n.descriptors = nzf['descriptors']\n",
    "            cg.add_node(d['node_id'])\n",
    "            cg.node[d['node_id']] = n\n",
    "        for e in data['links']:\n",
    "            cg.add_edge(e['source'], e['target'])\n",
    "            edge = Edge()\n",
    "            edge.source = cg.node[e['source']]\n",
    "            edge.destination = cg.node[e['target']]\n",
    "            edge['fundamental_matrix'] = e['fundamental_matrix']\n",
    "            edge['weight'] = e['weight']\n",
    "            nzf = np.load(BytesIO(pzip.read('{}_{}.npz'.format(e['source'], e['target']))))\n",
    "\n",
    "            edge._masks = pd.DataFrame(nzf['_masks'], index=nzf['_masks_idx'], columns=nzf['_masks_columns'])\n",
    "            edge.matches = pd.DataFrame(nzf['matches'], index=nzf['matches_idx'], columns=nzf['matches_columns'])\n",
    "            # Add a mock edge\n",
    "            cg.edge[e['source']][e['target']] = edge\n",
    "\n",
    "    return cg\n",
    "\n",
    "rebuilt = load('sampleout.project')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg == rebuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      True\n",
       "1      True\n",
       "2      True\n",
       "3      True\n",
       "4      True\n",
       "5      True\n",
       "6      True\n",
       "7      True\n",
       "8      True\n",
       "9      True\n",
       "10     True\n",
       "11     True\n",
       "12     True\n",
       "13     True\n",
       "14     True\n",
       "15     True\n",
       "16     True\n",
       "17     True\n",
       "18     True\n",
       "19     True\n",
       "20     True\n",
       "21     True\n",
       "22     True\n",
       "23     True\n",
       "24     True\n",
       "25     True\n",
       "26     True\n",
       "27     True\n",
       "28     True\n",
       "29     True\n",
       "       ... \n",
       "170    True\n",
       "171    True\n",
       "172    True\n",
       "173    True\n",
       "174    True\n",
       "175    True\n",
       "176    True\n",
       "177    True\n",
       "178    True\n",
       "179    True\n",
       "180    True\n",
       "181    True\n",
       "182    True\n",
       "183    True\n",
       "184    True\n",
       "185    True\n",
       "186    True\n",
       "187    True\n",
       "188    True\n",
       "189    True\n",
       "190    True\n",
       "191    True\n",
       "192    True\n",
       "193    True\n",
       "194    True\n",
       "195    True\n",
       "196    True\n",
       "197    True\n",
       "198    True\n",
       "199    True\n",
       "Name: source_image, dtype: bool"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rebuilt.edge[0][1].matches['source_image'] == 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    float64\n",
       "b    float64\n",
       "c    float64\n",
       "d    float64\n",
       "e    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(cg.edge[0][1].matches.values, columns=['a', 'b', 'c', 'd', 'e'],\n",
    "                  dtype=cg.edge[0][1].matches.dtypes)\n",
    "df.dtypes\n",
    "df = df.apply(pd.to_numeric)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([dtype('int64'), dtype('int64'), dtype('int64'), dtype('int64'),\n",
       "       dtype('float64')], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(cg.edge[0][1].matches.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "can't set attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/Users/jlaura/miniconda3/envs/autocnet/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   2774\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2775\u001b[0;31m                     \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2776\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: can't set attribute",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-cc8506b8152c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrebuilt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/jlaura/miniconda3/envs/autocnet/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   2775\u001b[0m                     \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m                 \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m     \u001b[0;31m# ----------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: can't set attribute"
     ]
    }
   ],
   "source": [
    "rebuilt.edge[0][1].matches.dtypes = cg.edge[0][1].matches.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_image</th>\n",
       "      <th>source_idx</th>\n",
       "      <th>destination_image</th>\n",
       "      <th>destination_idx</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [source_image, source_idx, destination_image, destination_idx, distance]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rebuilt.edge[0][2].matches[(rebuilt.edge[0][2].matches != cg.edge[0][2].matches).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg.edge[0][1].matches['source_image'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rebuilt.edge[0][1].matches['source_image'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__bytes__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__enter__', '__eq__', '__exit__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', '__unicode__', '__weakref__', '_check_if_open', '_complevel', '_complib', '_create_storer', '_filters', '_fletcher32', '_handle', '_mode', '_path', '_read_group', '_validate_format', '_write_to_group', 'append', 'append_to_multiple', 'close', 'copy', 'create_table_index', 'filename', 'flush', 'get', 'get_node', 'get_storer', 'groups', 'is_open', 'items', 'iteritems', 'keys', 'open', 'put', 'remove', 'root', 'select', 'select_as_coordinates', 'select_as_multiple', 'select_column']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot create a storer if the object is not existing nor a value are passed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-bd07da1659a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHDFStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'abc'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'/f'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jlaura/miniconda3/envs/autocnet/lib/python3.5/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36mget_storer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_storer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jlaura/miniconda3/envs/autocnet/lib/python3.5/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36m_create_storer\u001b[0;34m(self, group, format, value, append, **kwargs)\u001b[0m\n\u001b[1;32m   1202\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m                     raise TypeError(\n\u001b[0;32m-> 1204\u001b[0;31m                         \u001b[0;34m\"cannot create a storer if the object is not existing \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1205\u001b[0m                         \"nor a value are passed\")\n\u001b[1;32m   1206\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot create a storer if the object is not existing nor a value are passed"
     ]
    }
   ],
   "source": [
    "ax = np.random.randint(10, size=(3,3))\n",
    "with pd.HDFStore('abc' + '.h5', 'a') as h5f:\n",
    "    print(dir(h5f))\n",
    "    h5f.get_storer('/')\n",
    "    h5f._handle['/f'] =  x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls -alh test.msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from autocnet.utils.utils import make_homogeneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.random.randint(100, size=(10,2))\n",
    "make_homogeneous(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(x, columns=['x', 'y'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_homogeneous(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hash': None}\n"
     ]
    }
   ],
   "source": [
    "d = {}\n",
    "serial = None\n",
    "d['hash'] = serial\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hash': None}\n"
     ]
    }
   ],
   "source": [
    "serial = 123\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from uuid import uuid4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ac6dad2fb36d411b926ff0418b0091e9'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(uuid4())\n",
    "uuid4().hex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
