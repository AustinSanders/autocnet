{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # get file path\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('../..'))\n",
    "\n",
    "from scipy.misc import bytescale # store image array\n",
    "\n",
    "import autocnet\n",
    "\n",
    "from autocnet.examples import get_path # get file path\n",
    "from autocnet.fileio.io_gdal import GeoDataset # set handle, get image as array\n",
    "from autocnet.graph.network import CandidateGraph #construct adjacency graph\n",
    "from autocnet.matcher import feature_extractor as fe # extract features from image\n",
    "from autocnet.matcher.matcher import FlannMatcher # match features between images\n",
    "from autocnet.utils import visualization as vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# display graphs in separate window to be able to change size\n",
    "%pylab qt4\n",
    "# displays graphs in noteboook\n",
    "# %pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up for visualization : Construct an adjacency graph with features extracted\n",
    "-----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_dict = {\"../examples/Apollo15/AS15-M-0297_SML.png\"\n",
    "                  : [\"../examples/Apollo15/AS15-M-0298_SML.png\"], \n",
    "                  \"../examples/Apollo15/AS15-M-0298_SML.png\"\n",
    "                  : [\"../examples/Apollo15/AS15-M-0297_SML.png\"]}\n",
    "adjacencyGraph = CandidateGraph.from_adjacency(adjacency_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Keypoints must be extracted already, they have not been.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1127c95d25db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madjacencyGraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvex_hull_ratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/jlaura/github/autocnet/autocnet/graph/network.py\u001b[0m in \u001b[0;36mconvex_hull_ratio\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mideal_area\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpixel_area\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'keypoints'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Keypoints must be extracted already, they have not been.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvex_hull_ratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeypoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mideal_area\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Keypoints must be extracted already, they have not been."
     ]
    }
   ],
   "source": [
    "n = adjacencyGraph.node[0]\n",
    "n.convex_hull_ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<autocnet.graph.network.Edge at 0x11b570b70>"
      ]
     },
     "execution_count": 5,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "adjacencyGraph.edge[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacencyGraph.extract_features(method='sift', extractor_parameters={'nfeatures':25})\n",
    "imageName1 = adjacencyGraph.node[0]['image_name']\n",
    "imageName2 = adjacencyGraph.node[1]['image_name']\n",
    "print(imageName1)\n",
    "print(imageName2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use visualization utility plotFeatures() to plot the features of a single image\n",
    "-----------------------------------------------------------------------------------------\n",
    "In this example, we plot both images to open in separate windows\n",
    "1. Features found in AS15-M-0298_SML.png\n",
    "2. Features found in AS15-M-0297_SML.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "keypoints1 = adjacencyGraph.get_keypoints(imageName1)\n",
    "vis.plotFeatures(imageName1, keypoints1)\n",
    "\n",
    "plt.figure(1)\n",
    "keypoints2 = adjacencyGraph.get_keypoints(imageName2)\n",
    "vis.plotFeatures(imageName2, keypoints2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hull = adjacencyGraph.covered_area(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "keypoints2 = adjacencyGraph.get_keypoints(imageName2)\n",
    "vis.plotFeatures(imageName1, keypoints2)\n",
    "kp2 = np.empty((len(keypoints2), 2))\n",
    "for i, j in enumerate(keypoints2):\n",
    "    kp2[i] = j.pt[0], j.pt[1]\n",
    "plt.plot(kp2[hull.vertices,0], kp2[hull.vertices,1], 'r--', lw=2)\n",
    "print(adjacencyGraph.node[0]['handle'].pixel_area)\n",
    "print(hull.volume / adjacencyGraph.node[0]['handle'].pixel_area )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hull.volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(adjacencyGraph[0][1])\n",
    "adjacencyGraph[0][1]\n",
    "type(adjacencyGraph.edge[0][1])\n",
    "print(adjacencyGraph.edge[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(0)\n",
    "plt.close(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use visualization utility plotAdjacencyGraphFeatures() to plot the features on all images of the graph in a single figure.\n",
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plotAdjacencyGraphFeatures(adjacencyGraph, featurePointSize=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up for visualization : Find matches in Adjacency Graph\n",
    "-----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a FLANN matcher\n",
    "matcher = FlannMatcher()\n",
    "\n",
    "# Loop through the nodes on the graph and feature descriptors to the matcher\n",
    "for node, attributes in adjacencyGraph.nodes_iter(data=True):\n",
    "    matcher.add(attributes['descriptors'], key=node)\n",
    "    \n",
    "# build KD-Tree using the feature descriptors\n",
    "matcher.train()\n",
    "\n",
    "# Loop through the nodes on the graph to find all features that match at 1 neighbor\n",
    "# These matches are returned as PANDAS dataframes and added to the adjacency graph\n",
    "for node, attributes in adjacencyGraph.nodes_iter(data=True):\n",
    "    descriptors = attributes['descriptors']\n",
    "    matches = matcher.query(descriptors, node, k=2)\n",
    "    adjacencyGraph.add_matches(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use visualization utility plotAdjacencyGraphMatches() to plot the matches between two images of the graph in a single figure.\n",
    "------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plotAdjacencyGraphMatches(imageName1, \n",
    "                              imageName2, \n",
    "                              adjacencyGraph, \n",
    "                              aspectRatio=0.44, \n",
    "                              featurePointSize=3,\n",
    "                              lineWidth=1,\n",
    "                              saveToFile='myimage.png')\n",
    "plt.figure(0)\n",
    "img = plt.imread('myimage.png')\n",
    "plt.imshow(img)\n",
    "\n",
    "\n",
    "vis.plotAdjacencyGraphMatches(imageName1, \n",
    "                              imageName2, \n",
    "                              adjacencyGraph, \n",
    "                              aspectRatio=0.44, \n",
    "                              featurePointSize=10,\n",
    "                              lineWidth=3,\n",
    "                              saveToFile='myimage.png')\n",
    "plt.figure(1)\n",
    "img = plt.imread('myimage.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an earlier attempt at plotting images within the same display box.<br>\n",
    "Features are plotted.<br>\n",
    "Lines are not drawn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(2)\n",
    "vis.plotAdjacencyGraphMatchesSingleDisplay(imageName1, imageName2, adjacencyGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(0)\n",
    "plt.close(1)\n",
    "plt.close(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}