{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from shapely.geometry import Polygon as Poly, Point\n",
    "from shapely.affinity import scale\n",
    "import ogr\n",
    "import time\n",
    "from scipy.spatial import Voronoi\n",
    "\n",
    "from autocnet.examples import get_path\n",
    "from autocnet.graph.network import CandidateGraph\n",
    "from autocnet.cg import cg\n",
    "\n",
    "from unittest.mock import Mock\n",
    "from unittest.mock import MagicMock\n",
    "from autocnet.graph import edge\n",
    "from autocnet.graph import node\n",
    "from autocnet.graph.node import Node\n",
    "from plio.io import io_gdal\n",
    "\n",
    "from autocnet.utils.utils import array_to_poly\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "%pylab inline\n",
    "figsize(20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def scale_point(point, centroid, scalar):\n",
    "    point = np.asarray(point)\n",
    "    centroid = centroid[:2]\n",
    "    vector = ((point - centroid)*scalar) + centroid\n",
    "    return (vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def reproj_point(H, point):\n",
    "    \"\"\"\n",
    "    Reproject a pixel in one image into another image\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    H : object\n",
    "        (3,3) ndarray or Homography object\n",
    "        \n",
    "    corner : iterable\n",
    "             A 2 element iterable in the form x, y\n",
    "    \"\"\"\n",
    "    if len(point) == 2:\n",
    "        coords = np.array([point[0],point[1],1])\n",
    "    elif len(point) == 3:\n",
    "        coords = np.asarray(point)\n",
    "        coords *= coords[-1]  # Homogenize\n",
    "    \n",
    "    return H.dot(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def compute_intersection(source, graph, clean_keys=[]):\n",
    "    if type(source) is int:\n",
    "        source = graph.node[source]\n",
    "    \n",
    "    source_corners = source.geodata.xy_corners\n",
    "    source_poly = Poly(source_corners)\n",
    "    \n",
    "    source_gdf = gpd.GeoDataFrame({'source_geom': [source_poly], 'source_node': [source['node_id']]}).set_geometry('source_geom')\n",
    "    \n",
    "    proj_list = []\n",
    "    proj_nodes = []\n",
    "    # Begin iterating through the nodes in the graph excluding the source node\n",
    "    for n in graph.nodes_iter():\n",
    "        if n == source['node_id']:\n",
    "            continue\n",
    "        \n",
    "        # Define the edge, matches, and destination based on the zero node and the nth node\n",
    "        destination = graph.node[n]\n",
    "        destination_corners = destination.geodata.xy_corners\n",
    "        \n",
    "        edge = graph.edge[source['node_id']][destination['node_id']]\n",
    "        \n",
    "        # Will still need the check but the helper function will make these calls much easier to understand\n",
    "        if source['node_id'] > destination['node_id']:\n",
    "            kp2 = edge.get_keypoints('source', clean_keys = clean_keys, homogeneous = True)\n",
    "            kp1 = edge.get_keypoints('destination', clean_keys = clean_keys, homogeneous = True)\n",
    "        else:\n",
    "            kp2 = edge.get_keypoints('destination', clean_keys = clean_keys, homogeneous = True)\n",
    "            kp1 = edge.get_keypoints('source', clean_keys = clean_keys, homogeneous = True)\n",
    "\n",
    "        # If the source image has coordinate transformation data\n",
    "        if (source.geodata.coordinate_transformation.this != None) and \\\n",
    "        (destination.geodata.coordinate_transformation.this != None):\n",
    "            proj_poly = Poly(destination.geodata.xy_corners)\n",
    "            \n",
    "        # Else, use the homography transform to get an intersection of the two images\n",
    "        else:\n",
    "            H, mask = cv2.findHomography(kp2.values, kp1.values, cv2.RANSAC, 2.0)\n",
    "            proj_corners = []\n",
    "            for c in destination_corners:\n",
    "                x, y, h = reproj_point(H, c)\n",
    "                x /= h\n",
    "                y /= h\n",
    "                h /= h\n",
    "                proj_corners.append((x, y))\n",
    "                \n",
    "            proj_poly = Poly(proj_corners)\n",
    "        \n",
    "        proj_list.append(proj_poly)\n",
    "        proj_nodes.append(n)\n",
    "    \n",
    "    proj_gdf = gpd.GeoDataFrame({'proj_geom': proj_list, 'proj_node': proj_nodes}).set_geometry('proj_geom')\n",
    "       \n",
    "    intersect_gdf = gpd.overlay(source_gdf, proj_gdf, how='intersection')\n",
    "    intersect_gdf = intersect_gdf.rename(columns = {'geometry':'intersect_geom'}).set_geometry('intersect_geom')\n",
    "    intersect_gdf['overlaps_all'] = intersect_gdf.geometry.apply(lambda x:proj_gdf.geometry.contains(scale(x, .9, .9)).all())\n",
    "    intersection = intersect_gdf.query('overlaps_all == True').set_geometry('intersect_geom')\n",
    "    return intersection, proj_gdf, source_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def vor(graph, clean_keys=[], verbose=False, s = 30):\n",
    "    \n",
    "    neighbors_dict = nx.degree(graph)\n",
    "    if not all(value == len(graph.neighbors(graph.nodes()[0])) for value in neighbors_dict.values()):\n",
    "        raise AssertionError('The graph is not complete')\n",
    "    \n",
    "    # Have compute_intersection get the intersections of the subgraph, the projected nodes in the\n",
    "    # subgraph, and the source image all in there own geopandas dataframes\n",
    "    intersection, proj_gdf, source_gdf = compute_intersection(graph.nodes()[0], graph, clean_keys)\n",
    "    \n",
    "    # Get the intersection for the given subgrpah\n",
    "    intersection_ind = intersection.query('overlaps_all == True').index.values[0]\n",
    "    \n",
    "    source_node = graph.nodes()[0]\n",
    "    # Set the source, destination, edge, matches, and keypoints(kps) based on the first edge in the subgraph\n",
    "    # which should be the smallest node in the graph\n",
    "    for e in graph.edges():\n",
    "        # Recompute the intersection if the source node of the n + 1 edge is different from the n edge\n",
    "        if e[0] != source_node:\n",
    "            source_node = e[0]\n",
    "            intersection, proj_gdf, source_gdf = compute_intersection(source_node, graph, clean_keys)\n",
    "            intersection_ind = intersection.query('overlaps_all == True').index.values[0]\n",
    "            \n",
    "\n",
    "        edge = graph.edge[e[0]][e[1]]\n",
    "        matches, mask = edge.clean(clean_keys = clean_keys)\n",
    "        kps = edge.get_keypoints('source', clean_keys = clean_keys, homogeneous = True)\n",
    "\n",
    "        # Get all of the keypoints that are inside of the intersection then mask out the points\n",
    "        # in kps that lie outside of the intersection\n",
    "        # All of these operations on kps are extremely expensive\n",
    "        kps['geometry'] = kps.apply(lambda x: Point(x['x'], x['y']), axis = 1)\n",
    "        kps.mask = kps['geometry'].apply(lambda x: intersection.geometry.contains(x).all())\n",
    "        \n",
    "        # Creates a mask for displaying the voronoi points\n",
    "        # Currently erronious and produces NaN values\n",
    "        # mask[mask] = kps.mask\n",
    "        # edge.masks = ('voronoi', mask)\n",
    "\n",
    "        keypoints = []\n",
    "        kps[kps.mask].apply(lambda x: keypoints.append((x['x'], x['y'])), axis = 1)\n",
    "        coords = source_gdf.geometry.apply(lambda x:scale(x, s, s).exterior.coords)\n",
    "\n",
    "        for point in coords:\n",
    "            keypoints = np.vstack((keypoints, point))\n",
    "        \n",
    "        vor = Voronoi(keypoints)\n",
    "        \n",
    "        # For weight computation\n",
    "        # Should move to its own method\n",
    "        voronoi_df = pd.DataFrame(data = kps, columns = ['x', 'y', 'weight'])\n",
    "        \n",
    "        i = 0\n",
    "        vor_points = np.asarray(vor.points)\n",
    "        for region in vor.regions:\n",
    "            region_point = vor_points[np.argwhere(vor.point_region==i)]\n",
    "            if not -1 in region:\n",
    "                polygon_points = [vor.vertices[i] for i in region]\n",
    "                if len(polygon_points) != 0:\n",
    "                    polygon = Poly(polygon_points)\n",
    "                    poly_area = polygon.intersection(intersection.geometry[intersection_ind]).area\n",
    "                    voronoi_df.loc[(voronoi_df[\"x\"] == region_point[0][0][0]) & \n",
    "                                   (voronoi_df[\"y\"] == region_point[0][0][1]), \n",
    "                                   'weight'] = poly_area\n",
    "            i+=1\n",
    "        \n",
    "        edge['weights']['vor_weight'] = voronoi_df['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acpaquette/autocnet/autocnet/transformation/fundamental_matrix.py:252: UserWarning: Unable to apply MLE.  Not enough correspondences.  Returning with a RANSAC computed F matrix.\n",
      "  warnings.warn(\"Unable to apply MLE.  Not enough correspondences.  Returning with a RANSAC computed F matrix.\")\n"
     ]
    }
   ],
   "source": [
    "#Point to the adjacency Graph\n",
    "adjacency = get_path('vor_adjacency1.json')\n",
    "basepath = get_path('Apollo15')\n",
    "cang = CandidateGraph.from_adjacency(adjacency, basepath=basepath)\n",
    "\n",
    "#Apply SIFT to extract f\"eatures\n",
    "cang.extract_features(method='sift', extractor_parameters={'nfeatures':1500})\n",
    "\n",
    "#Match\n",
    "cang.match()\n",
    "\n",
    "#Apply outlier detection\n",
    "# cg.apply_func_to_edges(Edge.symmetry_check)\n",
    "cang.symmetry_checks()\n",
    "# cg.apply_func_to_edges(Edge.ratio_check)\n",
    "cang.ratio_checks()\n",
    "\n",
    "\n",
    "#Compute a homography and apply RANSAC\n",
    "cang.apply_func_to_edges(\"compute_fundamental_matrix\", clean_keys=['ratio', 'symmetry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_weights(cang, clean_keys = [], node_id=None, clique = False,):\n",
    "    if clique:\n",
    "        cliques = compute_cliques(cang, node_id)\n",
    "        for g in cliques:\n",
    "            subgraph = cang.create_node_subgraph(g)\n",
    "            cg.vor(subgraph, clean_keys)\n",
    "    else:\n",
    "        for e in cang.edges_iter():\n",
    "            subgraph = cang.create_node_subgraph(e)\n",
    "            cg.vor(subgraph, clean_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def compute_cliques(graph, node_id):\n",
    "    if node_id is not None:\n",
    "        return list(nx.cliques_containing_node(graph, nodes=node_id))\n",
    "    else:\n",
    "        return list(nx.find_cliques(graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1514979999999966\n",
      "2.8140520000000038\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "compute_weights(cang, clique = True, clean_keys = ['fundamental'])\n",
    "print(time.clock() - start)\n",
    "\n",
    "start = time.clock()\n",
    "compute_weights(cang, clique = False, clean_keys = ['fundamental'])\n",
    "print(time.clock() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1148349999999994\n",
      "2.8084049999999934\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "cang.compute_vor_weight(clean_keys = ['fundamental'], clique = True)\n",
    "print(time.clock() - start)\n",
    "\n",
    "start = time.clock()\n",
    "cang.compute_vor_weight(clean_keys = ['fundamental'], clique = False)\n",
    "print(time.clock() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "source_keypoint_df = pd.DataFrame({'x': (15, 18, 18, 12, 12), 'y': (6, 10, 15, 15, 10)})\n",
    "destination_keypoint_df = pd.DataFrame({'x': (5, 8, 8, 2, 2), 'y': (1, 5, 10, 10, 5)})\n",
    "keypoint_matches = [[0, 0, 1, 0],\n",
    "                    [0, 1, 1, 1],\n",
    "                    [0, 2, 1, 2],\n",
    "                    [0, 3, 1, 3],\n",
    "                    [0, 4, 1, 4]]\n",
    "\n",
    "matches_df = pd.DataFrame(data = keypoint_matches, columns = ['source_image', 'source_idx', \n",
    "                                                                  'destination_image', 'destination_idx'])\n",
    "# Source and Destination Node Setup\n",
    "source_node = MagicMock(spec = Node())\n",
    "destination_node = MagicMock(spec = Node())\n",
    "\n",
    "source_node.get_keypoint_coordinates = MagicMock(return_value=source_keypoint_df)\n",
    "destination_node.get_keypoint_coordinates = MagicMock(return_value=destination_keypoint_df)\n",
    "\n",
    "source_geodata = Mock(spec = io_gdal.GeoDataset)\n",
    "destination_geodata = Mock(spec = io_gdal.GeoDataset)\n",
    "\n",
    "source_node.geodata = source_geodata\n",
    "destination_node.geodata = destination_geodata\n",
    "\n",
    "source_node.geodata.coordinate_transformation.this = None\n",
    "destination_node.geodata.coordinate_transformation.this = None\n",
    "\n",
    "source_corners = [(0, 0),\n",
    "                  (20, 0),\n",
    "                  (20, 20),\n",
    "                  (0, 20)]\n",
    "\n",
    "destination_corners = [(0, 0),\n",
    "                       (20, 0),\n",
    "                       (20, 20),\n",
    "                       (0, 20)]\n",
    "\n",
    "source_node.geodata.xy_corners = source_corners\n",
    "destination_node.geodata.xy_corners = destination_corners\n",
    "\n",
    "# Edge Setup\n",
    "e = edge.Edge(source = source_node, destination = destination_node)\n",
    "\n",
    "e.clean = MagicMock(return_value=(matches_df, None))\n",
    "e.matches = matches_df\n",
    "\n",
    "def side_effect(node, clean_keys, **kwargs):\n",
    "    if type(node) is str:\n",
    "        node = node.lower()\n",
    "\n",
    "    if isinstance(node, Node):\n",
    "        node = node['node_id']\n",
    "\n",
    "    if node == \"source\" or node == \"s\" or node == source_node['node_id']:\n",
    "        return e.source.get_keypoint_coordinates().copy(deep=True)\n",
    "    if node == \"destination\" or node == \"d\" or node == destination_node['node_id']:\n",
    "        return e.destination.get_keypoint_coordinates().copy(deep=True)\n",
    "    \n",
    "my_dict_source = {'node_id':0}\n",
    "\n",
    "def getitem_source(name):\n",
    "    return my_dict_source[name]\n",
    "\n",
    "my_dict_destination = {'node_id':1}\n",
    "\n",
    "def getitem_destination(name):\n",
    "    return my_dict_destination[name]\n",
    "\n",
    "source_node.__getitem__.side_effect = getitem_source\n",
    "destination_node.__getitem__.side_effect = getitem_destination\n",
    "    \n",
    "e.get_keypoints = MagicMock(side_effect = side_effect)\n",
    "\n",
    "cang = MagicMock(spec = CandidateGraph())\n",
    "\n",
    "cang.nodes = MagicMock(return_value=([0, 1]))\n",
    "cang.node = [source_node, destination_node]\n",
    "cang.nodes_iter = MagicMock(return_value=([0, 1]))\n",
    "cang.neighbors = MagicMock(return_value = [1])\n",
    "cang.edges = MagicMock(return_value=([(0, 1)]))\n",
    "cang.edge = {0:{1:e}, 1:{0:e}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.031369000000001535\n",
      "{'vor_weight': 0    22.50\n",
      "1    26.25\n",
      "2    37.50\n",
      "3    37.50\n",
      "4    26.25\n",
      "Name: weight, dtype: float64}\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "vor(cang, clean_keys = ['fundamental'])\n",
    "print(time.clock() - start)\n",
    "print(e['weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# adjacency = get_path('two_image_adjacency.json')\n",
    "# basepath = get_path('Apollo15')\n",
    "# cg = CandidateGraph.from_adjacency(adjacency, basepath=basepath)\n",
    "keypoint_df = pd.DataFrame({'x': (15, 18, 18, 12, 12), 'y': (6, 10, 15, 15, 10)})\n",
    "keypoint_matches = [[0, 0, 1, 0],\n",
    "                    [0, 1, 1, 1],\n",
    "                    [0, 2, 1, 2],\n",
    "                    [0, 3, 1, 3],\n",
    "                    [0, 4, 1, 4]]\n",
    "\n",
    "matches_df = pd.DataFrame(data = keypoint_matches, columns = ['source_image', 'source_idx', \n",
    "                                                                  'destination_image', 'destination_idx'])\n",
    "e = edge.Edge(source = source_node, destination = destination_node)\n",
    "\n",
    "e.clean = MagicMock(return_value=(matches_df, None))\n",
    "e.matches = matches_df\n",
    "\n",
    "source_node = MagicMock(spec = node.Node())\n",
    "destination_node = MagicMock(spec = node.Node())\n",
    "\n",
    "cang = MagicMock(spec = CandidateGraph())\n",
    "\n",
    "cang.nodes = MagicMock(return_value=([0, 1]))\n",
    "cang.node = [source_node, destination_node]\n",
    "cang.nodes_iter = MagicMock(return_value=([0, 1]))\n",
    "cang.neighbors = MagicMock(return_value=([0]))\n",
    "cang.edges = MagicMock(return_value=([(0, 1)]))\n",
    "cang.edge = {0:{1:e}, 1:{0:e}}\n",
    "\n",
    "source_node.get_keypoint_coordinates = MagicMock(return_value=keypoint_df)\n",
    "destination_node.get_keypoint_coordinates = MagicMock(return_value=keypoint_df)\n",
    "source_node['node_id'] = 0\n",
    "destination_node['node_id'] = 1\n",
    "\n",
    "def side_effect(node, clean_keys, **kwargs):\n",
    "    if type(node) is str:\n",
    "        node = node.lower()\n",
    "\n",
    "    if isinstance(node, Node):\n",
    "        node = node['node_id']\n",
    "\n",
    "    if node == \"source\" or node == \"s\" or node == source_node['node_id']:\n",
    "        return e.source.get_keypoint_coordinates()\n",
    "    if node == \"destination\" or node == \"d\" or node == destination_node['node_id']:\n",
    "        return e.destination.get_keypoint_coordinates()\n",
    "    \n",
    "e.get_keypoints = MagicMock(side_effect = side_effect)\n",
    "\n",
    "e.source = source_node\n",
    "e.destination = destination_node\n",
    "\n",
    "source_geodata = Mock(spec = io_gdal.GeoDataset)\n",
    "destination_geodata = Mock(spec = io_gdal.GeoDataset)\n",
    "\n",
    "e.source.geodata = source_geodata\n",
    "e.destination.geodata = destination_geodata\n",
    "\n",
    "source_corners = [(0, 0),\n",
    "                  (20, 0),\n",
    "                  (20, 20),\n",
    "                  (0, 20)]\n",
    "\n",
    "destination_corners = [(10, 5),\n",
    "                       (30, 5),\n",
    "                       (30, 25),\n",
    "                       (10, 25)]\n",
    "\n",
    "source_xy_extent = [(0, 20), (0, 20)]\n",
    "\n",
    "destination_xy_extent = [(10, 30), (5, 25)]\n",
    "\n",
    "source_poly = array_to_poly(source_corners)\n",
    "destination_poly = array_to_poly(destination_corners)\n",
    "\n",
    "vals = {(10, 5):(10, 5), (20, 5):(20, 5), (20, 20):(20, 20), (10, 20):(10, 20)}\n",
    "\n",
    "def latlon_to_pixel(i, j):\n",
    "    return vals[(i, j)]\n",
    "\n",
    "my_dict_source = {'node_id':0}\n",
    "\n",
    "def getitem_source(name):\n",
    "    return my_dict_source[name]\n",
    "\n",
    "my_dict_destination = {'node_id':1}\n",
    "\n",
    "def getitem_destination(name):\n",
    "    return my_dict_destination[name]\n",
    "\n",
    "source_node.__getitem__.side_effect = getitem_source\n",
    "destination_node.__getitem__.side_effect = getitem_destination\n",
    "\n",
    "e.source.geodata.latlon_to_pixel = MagicMock(side_effect = latlon_to_pixel)\n",
    "e.destination.geodata.latlon_to_pixel = MagicMock(side_effect = latlon_to_pixel)\n",
    "\n",
    "e.source.geodata.footprint = source_poly\n",
    "e.source.geodata.xy_corners = source_corners\n",
    "e.source.geodata.xy_extent = source_xy_extent\n",
    "e.destination.geodata.footprint = destination_poly\n",
    "e.destination.geodata.xy_corners = destination_corners\n",
    "e.destination.geodata.xy_extent = destination_xy_extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03340599999999938\n",
      "{'vor_weight': 0    22.50\n",
      "1    26.25\n",
      "2    37.50\n",
      "3    37.50\n",
      "4    26.25\n",
      "Name: weight, dtype: float64}\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "vor(cang, clean_keys = ['fundamental'])\n",
    "print(time.clock() - start)\n",
    "print(e['weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def vor_plot(graph, clean_keys = []):\n",
    "    \n",
    "    num_neighbors = len(graph.nodes()) - 1\n",
    "    for n in graph.nodes():\n",
    "        neighbors = len(graph.neighbors(n))\n",
    "        if neighbors != num_neighbors:\n",
    "            raise AssertionError('The graph is not complete')\n",
    "    \n",
    "    intersection, proj_gdf, source_gdf = compute_intersection(graph.nodes()[0], graph, clean_keys)\n",
    "    \n",
    "    source_node = graph.nodes()[0]\n",
    "\n",
    "    for e in graph.edges():\n",
    "        if e[0] != source_node:\n",
    "            source_node = e[0]\n",
    "            start_inter = time.clock()\n",
    "            intersection, proj_gdf, source_gdf = compute_intersection(source_node, graph, clean_keys)\n",
    "            \n",
    "        edge = graph.edge[e[0]][e[1]]\n",
    "        kps = edge.get_keypoints('source', clean_keys = clean_keys, homogeneous = True)\n",
    "        kps = kps[edge.vor_mask]\n",
    "        \n",
    "        vor = edge.voronoi\n",
    "    \n",
    "        i = 0\n",
    "        poly_array = []\n",
    "        vor_points = np.asarray(vor.points)\n",
    "        for region in vor.regions:\n",
    "            region_point = vor_points[np.argwhere(vor.point_region==i)]\n",
    "            if not -1 in region:\n",
    "                polygon_points = [vor.vertices[i] for i in region]\n",
    "                if len(polygon_points) != 0:\n",
    "                    polygon = Poly(polygon_points)\n",
    "                    poly_array.append(polygon)\n",
    "            i+=1\n",
    "            \n",
    "        poly_gdf = gpd.GeoDataFrame(data = poly_array, columns = ['geometry'])\n",
    "        vor_poly_gdf = gpd.overlay(poly_gdf, intersection, how='intersection')\n",
    "        \n",
    "        ax = proj_gdf.query('proj_node != ' + str(n)).plot(color='#388aff', alpha=0.1)\n",
    "        proj_gdf.query('proj_node == ' + str(n)).plot(color = 'g', alpha=0.1, ax = ax)\n",
    "        source_gdf.plot(color='r', alpha=0.1, ax=ax)\n",
    "        vor_poly_gdf.plot(cmap='Set1', alpha=.5, ax=ax)\n",
    "#             graph.edge[0][3].plot(clean_keys = ['fundamental'], ax = ax)\n",
    "        edge.source.plot(index_mask = edge.matches['destination_idx'], alpha = 0)\n",
    "        matplotlib.pyplot.scatter(kps['x'], kps['y'], color = 'black', alpha = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
