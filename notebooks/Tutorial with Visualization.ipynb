{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures as cf\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from autocnet.examples import get_path\n",
    "from autocnet.graph.network import CandidateGraph\n",
    "from autocnet.graph.edge import Edge\n",
    "from autocnet.matcher.matcher import FlannMatcher\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a 3 image adjacenecy graph\n",
    "\n",
    "Here we generate a three image adjacenecy graph, compute interest points, find matches, identify outliers, and finally compute fundamental matrices between all image pairs.  \n",
    "\n",
    "The below example is threaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 93 93\n",
      "2000 94 94\n",
      "2000 79 79\n"
     ]
    }
   ],
   "source": [
    "#Point to the adjacency Graph\n",
    "adjacency = get_path('three_image_adjacency.json')\n",
    "basepath = get_path('Apollo15')\n",
    "cg = CandidateGraph.from_adjacency(adjacency, basepath=basepath)\n",
    "\n",
    "#Apply SIFT to extract features\n",
    "cg.extract_features(method='sift', extractor_parameters={'nfeatures':500})\n",
    "\n",
    "#Match\n",
    "with cf.ThreadPoolExecutor(max_workers=3) as ex:\n",
    "    #Match\n",
    "    jobs = [ex.submit(e.match) for s, d, e in cg.edges_iter(data=True)]\n",
    "    [j.result() for j in jobs]\n",
    "    \n",
    "    # Symmetry Outlier\n",
    "    jobs = [ex.submit(e.symmetry_check) for s, d, e in cg.edges_iter(data=True)]\n",
    "    [j.result() for j in jobs]\n",
    "\n",
    "    #Ratio Outlier\n",
    "    jobs = [ex.submit(e.ratio_check) for s, d, e in cg.edges_iter(data=True)]\n",
    "    [j.result() for j in jobs]\n",
    "\n",
    "    #Compute the Fundamental Matrix (F)\n",
    "    jobs = [ex.submit(e.compute_fundamental_matrix,\n",
    "                      clean_keys=['symmetry', 'ratio']) for s, d, e in cg.edges_iter(data=True)]\n",
    "    [j.result() for j in jobs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serial\n",
    "As above, but this example utilizes a single core.  The API is potentially less complex to utilize, but the cost is overall performance.  These two examples, with just three small iamges, are too small to perform meaningfully different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Point to the adjacency Graph\n",
    "adjacency = get_path('three_image_adjacency.json')\n",
    "basepath = get_path('Apollo15')\n",
    "cg = CandidateGraph.from_adjacency(adjacency, basepath=basepath)\n",
    "\n",
    "#Apply SIFT to extract features\n",
    "cg.extract_features(method='sift', extractor_parameters={'nfeatures':500})\n",
    "\n",
    "#Match\n",
    "cg.match_features()\n",
    "\n",
    "#Symmetry Outlier\n",
    "cg.symmetry_checks()\n",
    "\n",
    "#Ratio Outlier\n",
    "cg.ratio_checks()\n",
    "\n",
    "#Compute the Fundamental Matrix (F)\n",
    "cg.compute_fundamental_matrices(clean_keys=['ratio', 'symmetry'], method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figsize(20,20)\n",
    "cg[1][2].plot(clean_keys=['fundamental'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The graph object:\n",
    "The underlying data structure is a graph, where each node is an image and each edge is the connectivity between nodes.  Nodes and Edges are classes with associated attributes and methods.  This notebook primarily focuses on the plotting functionality on the graph (and graph components).\n",
    "\n",
    "In these notebooks, the graph object is being stored in the variable `cg`.  Access to nodes and edges is positional.\n",
    "\n",
    "  * To access a node in the graph:  `cg[node_idx]`, e.g. `cg[0]`.\n",
    "  * To access an edge in the graph: `cg[source_idx][destination_idx]`, e.g. `cg[0][1]`\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cg.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot features at an individual node, e.g. a single image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All defaults are used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cg.node[1].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example specifies a plotting layout, passing in an axis object and passes along a color.  All the MatPlotLib plotting arguments are supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax1 = plt.subplot(1,1,1)\n",
    "ax = cg.node[0].plot(ax=ax1, color='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Matches on an Edge\n",
    "The plotting capability on a given node is limited to a single image; one can envision the node as being the image with all associated metadata and derived information.  The edge represents the overlap between images and resultant shared information, e.g. point correspondences, a homography, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the matches between an edge using two outlier detector masks\n",
    "To get a rough idea of what a 'good' results should be, we should see no, or few, lines which intersect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "ax = cg.edge[0][1].plot(clean_keys=['ratio', 'symmetry', 'fundamental'], ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now plot with the added, ransac computed mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cg.edge[0][1].plot(clean_keys=['ratio', 'symmetry', 'fundamental'], line_kwargs={'linewidth':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Coverage Metric\n",
    "We compute a coverage metric by utilizing the homography to project the destination image corner pixel coordinates into the source image and computing the intersection.  This is a rough estimate that is as good (or poor) as the homography."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "H = cg.edge[0][1].homography\n",
    "print('Not zero is good:', H.determinant)\n",
    "print('Not huge is good: ', H.condition)\n",
    "print('Shifts less than one pixel in all directions are good:', H.rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Ideal coverage would be 1.0\n",
    "cg.edge[0][1].coverage_ratio(clean_keys=['ransac'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above suggests that the quality is a function of the homography.  Just how good is the homography?  We can use the determinant (something near 1 is bad), the condition (a very large number, e.g. $10^15$ is bad), or the RMSE (reported in the x and y directions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing Keypoint Information\n",
    "Here we want to explore the attributes of the keypoints, using the masking information, e.g. the outlier detection methods.  The question is, what are the characteristics of those keypoints that have made it through the outlier detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skp, dkp = cg.edge[0][1].keypoints(clean_keys=['ratio', 'symmetry', 'ransac'])\n",
    "display(skp)\n",
    "display(dkp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subpixel Register\n",
    "We suggest only subpixel registering 'good' candidate matches as the subpixel registration process can be time consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cg.edge[0][1].subpixel_register(clean_keys=['fundamental', 'symmetry', 'ratio'],template_size=5, search_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cg.edge[0][1].plot(clean_keys=['ratio', 'symmetry', 'fundamental', 'subpixel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cg.edge[0][1].plot(clean_keys=['ratio', 'symmetry', 'fundamental', 'subpixel'], line_kwargs={'linewidth':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Suppression vis Disk Covering\n",
    "This method seeks to keep the $k$ strongest correlations with a good spatial distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cg.edge[0][1].suppress(k=100)\n",
    "\n",
    "# Plot, in blue the points that passed all outlier detectors so far\n",
    "cg.edge[0][1].plot(clean_keys=['ratio', 'symmetry', 'fundamental', 'subpixel'], line_kwargs={'linewidth':0})\n",
    "# Overlay, in red, the points that remain after suppression\n",
    "cg.edge[0][1].plot(clean_keys=['suppression'], line_kwargs={'linewidth':0}, scatter_kwargs={'color':'red'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
