{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import types\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "import itertools\n",
    "\n",
    "from autocnet.examples import get_path\n",
    "from autocnet.graph.network import CandidateGraph\n",
    "from autocnet.graph.edge import Edge\n",
    "from autocnet.matcher.matcher import FlannMatcher\n",
    "from autocnet.matcher.suppression_funcs import distance, error\n",
    "from autocnet.utils.utils import normalize_vector\n",
    "from autocnet.fileio.io_controlnetwork import to_isis\n",
    "from autocnet.matcher.subpixel import clip_roi\n",
    "from autocnet.matcher.matcher import pattern_match\n",
    "\n",
    "from IPython.display import display\n",
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "%pylab inline\n",
    "import line_profiler\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a 2 image adjacenecy graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jlaura/github/autocnet/autocnet/matcher/outlier_detector.py:256: UserWarning: Unable to optimally solve.  Returning with 34 points\n",
      "  warnings.warn('Unable to optimally solve.  Returning with {} points'.format(len(result)))\n"
     ]
    }
   ],
   "source": [
    "#Point to the adjacency Graph\n",
    "adjacency = get_path('three_image_adjacency.json')\n",
    "basepath = get_path('Apollo15')\n",
    "cg = CandidateGraph.from_adjacency(adjacency, basepath=basepath)\n",
    "\n",
    "#Apply SIFT to extract features\n",
    "cg.extract_features(method='sift')\n",
    "\n",
    "#Match\n",
    "cg.match_features()\n",
    "    \n",
    "#Apply outlier detection\n",
    "cg.symmetry_checks()\n",
    "cg.ratio_checks()\n",
    "\n",
    "\n",
    "#Compute a homography and apply RANSAC\n",
    "cg.compute_fundamental_matrices(clean_keys=['symmetry', 'ratio'])\n",
    "cg.suppress(clean_keys=['fundamental'], suppression_func=error, k=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnet = cg.get_cnet(clean_keys=['suppression'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_isis('out.cnet', cnet, mode='wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figsize(10,10)\n",
    "cg[1][2].plot(clean_keys=['suppression'], line_kwargs={'linewidth':0})\n",
    "show()\n",
    "cg[0][1].plot(clean_keys=['suppression'], line_kwargs={'linewidth':0})\n",
    "show()\n",
    "cg[0][2].plot(clean_keys=['suppression'], line_kwargs={'linewidth':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cg.compute_triangular_cycles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = set([1,2,3])\n",
    "x.difference(set([2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(itertools.combinations(*cg.compute_triangular_cycles(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(cg[0][1].matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = cg.edge[0][1]\n",
    "F = e.fundamental_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import leastsq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.]] \n",
      " [[  0.00000000e+00   1.07632759e-08   1.21069353e-04  -9.99799731e-01]\n",
      " [  1.48693064e-08   0.00000000e+00   3.11836738e-01   2.00115329e-02]\n",
      " [  3.15128726e-04   2.88985699e-01   0.00000000e+00   1.92813801e-04]]\n"
     ]
    }
   ],
   "source": [
    "def cost_function():\n",
    "    pass\n",
    "\n",
    "def triangulate(x, x1, p, p1):\n",
    "    \"\"\"\n",
    "    Triangulate sets of correspondences using estimated cameras\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : ndarray\n",
    "        (n,2) x,y coordinates or (n,3) x,y homogeneous coordinates\n",
    "    \n",
    "    x1 : ndarray\n",
    "        (n,2) x,y coordinates or (n,3) x,y homogeneous coordinates\n",
    "        \n",
    "    p : ndarray\n",
    "        (3,4) camera matrix\n",
    "        \n",
    "    p1 : ndarray\n",
    "         (3,4 camera matrix)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "u, s, v = np.linalg.svd(F)\n",
    "e = u[:,2] # Where entries are?\n",
    "e1 = np.array([[0, e[2], -e[1]],\n",
    "               [-e[2], 0, e[0]],\n",
    "               [e[1], -e[0], 0]])\n",
    "p1 = np.zeros((3,4))\n",
    "p1[:,:3] = (e1 * F)\n",
    "p1[:,3] = e\n",
    "p = np.eye(3,4)\n",
    "\n",
    "valid_coords = F.mas\n",
    "pgs = lstsq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F.error.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(e.matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below defaults to using the fundamental mask, but a better mask is probably the suppression base mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_base(edge, ax=None, clean_keys=[], image_space=100,\n",
    "              scatter_kwargs={}, line_kwargs={}, image_kwargs={}):\n",
    "    \"\"\"\n",
    "    Plot the correspondences for a given edge\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    edge : object\n",
    "           A graph edge object\n",
    "\n",
    "    ax : object\n",
    "         A MatPlotLIb axes object\n",
    "\n",
    "    clean_keys : list\n",
    "                 of strings of masking array names to apply\n",
    "\n",
    "    image_space : int\n",
    "                  The number of pixels to insert between the images\n",
    "\n",
    "    scatter_kwargs : dict\n",
    "                     of MatPlotLib arguments to be applied to the scatter plots\n",
    "\n",
    "    line_kwargs : dict\n",
    "                  of MatPlotLib arguments to be applied to the lines connecting matches\n",
    "\n",
    "    image_kwargs : dict\n",
    "                   of MatPlotLib arguments to be applied to the image rendering\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ax : object\n",
    "         A MatPlotLib axes object.  Either the argument passed in\n",
    "         or a new object\n",
    "    \"\"\"\n",
    "\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Plot setup\n",
    "    ax.set_title('Matching: {} to {}'.format(edge.source.image_name,\n",
    "                                             edge.destination.image_name))\n",
    "    ax.margins(tight=True)\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Image plotting\n",
    "    source_array = edge.source.get_array()\n",
    "    destination_array = edge.destination.get_array()\n",
    "\n",
    "    s_shape = source_array.shape\n",
    "    d_shape = destination_array.shape\n",
    "\n",
    "    y = max(s_shape[0], d_shape[0])\n",
    "    x = s_shape[1] + d_shape[1] + image_space\n",
    "    composite = np.zeros((y, x))\n",
    "\n",
    "    composite[:, :s_shape[1]] = source_array\n",
    "    composite[:, s_shape[1] + image_space:] = destination_array\n",
    "\n",
    "    if 'cmap' in image_kwargs:\n",
    "        cmap = image_kwargs['cmap']\n",
    "    else:\n",
    "        cmap = 'Greys'\n",
    "\n",
    "    ax.imshow(composite, cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "figsize(20,20)\n",
    "\n",
    "plotfig = False\n",
    "\n",
    "def deepen(nodes, threshold=4, base_mask='fundamental'):\n",
    "    \n",
    "    def _process(a,b, threshold, base_mask):        \n",
    "        # Maintain node/edge ordering\n",
    "        if a[0] > a[1]:\n",
    "            a.reverse()\n",
    "    \n",
    "        if b[0] > b[1]:\n",
    "            b.reverse()\n",
    "    \n",
    "        ab = cg[a[0]][a[1]]\n",
    "        bc = cg.edge[b[0]][b[1]]\n",
    "\n",
    "        if not 'depth' in bc.masks.columns:\n",
    "            bc.masks['depth'] = bc.masks[base_mask]\n",
    "\n",
    "        \n",
    "        # F and masks from the edge we are deepening (target)\n",
    "        F = bc.fundamental_matrix\n",
    "        \n",
    "        # Matched points from the edge we are using to deepen (source)\n",
    "        base_mask = ab.masks[base_mask]\n",
    "        match_idx = ab.matches[base_mask]\n",
    "\n",
    "        max_distance = match_idx['distance'].max() * 1.5\n",
    "        max_distance = 200\n",
    "        # Edge AB points that we want to search for in BC\n",
    "        ab_x = ab.source.get_keypoint_coordinates(index=match_idx['source_idx'], homogeneous=True)\n",
    "        \n",
    "        # All edge BC points that we want to try and match\n",
    "        bc_x = bc.destination.get_keypoint_coordinates(homogeneous=True).values\n",
    "        \n",
    "        # Compute and normalize the epipolar lines\n",
    "        l_norm = normalize_vector(ab_x.dot(F.T))\n",
    "\n",
    "        # Project every AB point to a BC epipolar line and find all BC points within threshold of said line\n",
    "        for i, (j, row) in enumerate(ab_x.iterrows()):\n",
    "            # j = index back into the network data structure for matches / keypoints\n",
    "            # i = the position index into the epipolar lines\n",
    "            if plotfig:\n",
    "                show_base(bc)\n",
    "                plot(row['x'], row['y'], 'ro')\n",
    "            \n",
    "            # Get the AB descriptor to use as the reference point\n",
    "            source_descriptor = ab.source.descriptors[j]\n",
    "\n",
    "            # Grab the correct epipolar line and compute the distance between all BC points and that said line\n",
    "            epipolar_line = l_norm[i]  \n",
    "            dist = np.abs(epipolar_line.dot(bc_x.T))\n",
    "            # Find all points within threshold of the current epipolar line\n",
    "            ids = np.where(dist <= threshold)[0]\n",
    "            \n",
    "            # Flags for finding the best match\n",
    "            flag_distance = math.inf\n",
    "            # Setup as a None array so that we can perform an if.any() check later\n",
    "            match = np.array([None])\n",
    "            \n",
    "            # Step through all of the candidate matches\n",
    "            colors = []\n",
    "            x = []\n",
    "            y = []\n",
    "            for k, v in zip(ids, dist[ids]):\n",
    "                didx = bc_x[k]\n",
    "                destination_descriptor = bc.destination.descriptors[k]\n",
    "                descriptor_distance = cv2.norm(source_descriptor, destination_descriptor)\n",
    "                colors.append(descriptor_distance)\n",
    "                x.append(didx[0] + 1112)\n",
    "                y.append(didx[1])\n",
    "                #if plotfig:\n",
    "                    #plot(didx[0]+ 100 + 1012, didx[1], 'bo', alpha=0.5, markersize=20)\n",
    "                \n",
    "                if descriptor_distance < flag_distance:# and descriptor_distance < max_distance:\n",
    "                    flag_distance = descriptor_distance\n",
    "                    \n",
    "                    match = didx\n",
    "                    iden = k\n",
    "                    \n",
    "            if match.any():\n",
    "                if plotfig:\n",
    "                    plot(match[0] + 100 + 1012, match[1], 'ro')\n",
    "\n",
    "                potential_match = bc.matches[(bc.matches['source_idx'] == row.name) &\n",
    "                                             (bc.matches['destination_idx'] == iden)]\n",
    "                \n",
    "                if len(potential_match) > 0:\n",
    "                    idx = potential_match.iloc[0].name\n",
    "                    if bc.masks['depth'].iloc[idx] == False:\n",
    "                        print('Already included')\n",
    "                    else:\n",
    "                        print('Adding')\n",
    "                        bc.masks['depth'].iloc[idx] = True\n",
    "                else:\n",
    "                    print('NEW MATCH....CRAP')\n",
    "                #print(bc.matches[bc.matches['destination_idx'] == match.name])\n",
    "            if plotfig:\n",
    "                sc = scatter(x, y, c=colors, s=200, alpha=0.25)\n",
    "                colorbar(sc)\n",
    "                show() \n",
    "\n",
    "\n",
    "    \n",
    "    subset_nodes = set(nodes)\n",
    "    for n in nodes:\n",
    "        sn = set([n])\n",
    "        o = list(subset_nodes.difference(sn))\n",
    "        \n",
    "        a = [n, o[0]]\n",
    "        b = [n, o[1]]\n",
    "        \n",
    "        _process(a,b,threshold, base_mask)\n",
    "        _process(b,a,threshold, base_mask)\n",
    "        \n",
    "\n",
    "\n",
    "#%lprun -f deepen deepen(cg.compute_triangular_cycles()[0], base_mask='suppression')\n",
    "deepen(cg.compute_triangular_cycles()[0], base_mask='suppression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "figsize(10,10)\n",
    "\n",
    "plotfig = False\n",
    "\n",
    "def deepen(nodes, threshold=1.5, base_mask='fundamental'):\n",
    "    \n",
    "    def _process(a,b, base_mask):        \n",
    "        # Maintain node/edge ordering\n",
    "        if a[0] > a[1]:\n",
    "            a.reverse()\n",
    "    \n",
    "        if b[0] > b[1]:\n",
    "            b.reverse()\n",
    "    \n",
    "        ab = cg[a[0]][a[1]]\n",
    "        bc = cg.edge[b[0]][b[1]]\n",
    "\n",
    "        ab_footprint = ab.source.geodata.footprint\n",
    "        bc_footprint = bc.destination.geodata.footprint\n",
    "        \n",
    "        #print(ab_footprint, bc_footprint)\n",
    "\n",
    "        \n",
    "        if not 'depth' in bc.masks.columns:\n",
    "            bc.masks['depth'] = bc.masks[base_mask]\n",
    "\n",
    "        \n",
    "        # F and masks from the edge we are deepening (target)\n",
    "        F = bc.fundamental_matrix\n",
    "        \n",
    "        # Matched points from the edge we are using to deepen (source)\n",
    "        base_mask = ab.masks[base_mask]\n",
    "        match_idx = ab.matches[base_mask]\n",
    "\n",
    "        # Edge AB points that we want to search for in BC\n",
    "        ab_x = ab.source.get_keypoint_coordinates(index=match_idx['source_idx'], homogeneous=True)\n",
    "        \n",
    "        # All edge BC points that we want to try and match\n",
    "        bc_x = bc.destination.get_keypoint_coordinates(homogeneous=True).values\n",
    "        \n",
    "        # Compute and normalize the epipolar lines\n",
    "        l_norm = normalize_vector(ab_x.dot(F.T))\n",
    "\n",
    "        # Project every AB point to a BC epipolar line and find all BC points within threshold of said line\n",
    "        for i, (j, row) in enumerate(ab_x.iterrows()):\n",
    "            # j = index back into the network data structure for matches / keypoints\n",
    "            # i = the position index into the epipolar lines\n",
    "            if plotfig:\n",
    "                show_base(bc)\n",
    "                plot(row['x'], row['y'], 'ro')\n",
    "            \n",
    "            # Get the AB descriptor to use as the reference point\n",
    "            # source_descriptor = ab.source.descriptors[j]\n",
    "            # Get the AB search\n",
    "            template = clip_roi(ab.source.geodata, (row['x'], row['y']), 15)\n",
    "            \n",
    "            # Grab the correct epipolar line and compute the distance between all BC points and that said line\n",
    "            epipolar_line = l_norm[i]  \n",
    "            dist = np.abs(epipolar_line.dot(bc_x.T))\n",
    "            # Find all points within threshold of the current epipolar line\n",
    "            ids = np.where(dist <= threshold)[0]\n",
    "            \n",
    "            # Flags for finding the best match\n",
    "            flag_distance = 0\n",
    "            # Setup as a None array so that we can perform an if.any() check later\n",
    "            match = np.array([None])\n",
    "            \n",
    "            # Step through all of the candidate matches\n",
    "            for k, v in zip(ids, dist[ids]):\n",
    "                didx = bc_x[k]\n",
    "                image = clip_roi(bc.destination.geodata, didx[:2], 111)\n",
    "                x, y, max_corr = pattern_match(template, image, upsampling=1)\n",
    "                #print(x, y, max_corr)\n",
    "\n",
    "                if plotfig:\n",
    "                    plot(didx[0]+ 100 + 1012, didx[1], 'bo', alpha=0.5, markersize=20)\n",
    "                    \n",
    "                # The maximum move\n",
    "                magnitude = True\n",
    "                if (abs(x) >= 2 and abs(y) >= 2) or (abs(x) >= 4 or abs(y) >= 4):\n",
    "                    magnitude = False\n",
    "                    \n",
    "                if max_corr > flag_distance and max_corr >= 0.9 and magnitude: # and descriptor_distance < max_distance:\n",
    "                    flag_distance = max_corr\n",
    "                    match = didx\n",
    "                    iden = k\n",
    "                    nx, ny = x, y\n",
    "                    \n",
    "            if match.any():\n",
    "                if plotfig:\n",
    "                    plot(match[0] + 100 + 1012, match[1], 'ro')\n",
    "\n",
    "                potential_match = bc.matches[(bc.matches['source_idx'] == row.name) &\n",
    "                                             (bc.matches['destination_idx'] == iden)]\n",
    "\n",
    "                if len(potential_match) > 0:\n",
    "                    idx = potential_match.iloc[0].name\n",
    "                    if bc.masks['depth'].iloc[idx] == True:\n",
    "                        print('ALREADY INCLUDED')\n",
    "                    else:\n",
    "                        print('INCLUDING')\n",
    "                        bc.masks['depth'].iloc[idx] = True\n",
    "                else:\n",
    "                    print('NEW', flag_distance, nx, ny)\n",
    "                    plot(row['x'], row['y'], 'ro')\n",
    "                    plot(match[0] + 100 + 1012, match[1], 'ro')\n",
    "                    show_base(bc)\n",
    "                    show()\n",
    "                #print(bc.matches[bc.matches['destination_idx'] == match.name])\n",
    "            if plotfig:\n",
    "                #sc = scatter(x, y, c=colors, s=200, alpha=0.25)\n",
    "                #colorbar(sc)\n",
    "                show() \n",
    "\n",
    "\n",
    "    \n",
    "    subset_nodes = set(nodes)\n",
    "    for n in nodes:\n",
    "        sn = set([n])\n",
    "        o = list(subset_nodes.difference(sn))\n",
    "        \n",
    "        a = [n, o[0]]\n",
    "        b = [n, o[1]]\n",
    "        \n",
    "        _process(a,b, base_mask)\n",
    "        _process(b,a, base_mask)\n",
    "        \n",
    "\n",
    "\n",
    "#%lprun -f deepen deepen(cg.compute_triangular_cycles()[0], base_mask='suppression')\n",
    "deepen(cg.compute_triangular_cycles()[0], base_mask='suppression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove the depth column for testing.\n",
    "for s, d, e, in cg.edges_iter(data=True):\n",
    "    e.masks.drop('depth', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "figsize(10,10)\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import hamming\n",
    "\n",
    "\n",
    "threshold = 4\n",
    "\n",
    "e = cg[0][1]\n",
    "F = e.fundamental_matrix\n",
    "match_idx = e.matches[F.mask]\n",
    "x = e.source.get_keypoint_coordinates(index=match_idx['source_idx'], homogeneous=True)\n",
    "x1 = e.destination.get_keypoint_coordinates(homogeneous=True).values\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Normalization allows for the dot product of a \n",
    "point to the normalized line returns the distance.\n",
    "\"\"\"\n",
    "def normalize_vector(line):\n",
    "    \"\"\"\n",
    "    Normalize the vector.\n",
    "    \"\"\"\n",
    "    if isinstance(line, pd.DataFrame):\n",
    "        line = line.values\n",
    "    n = np.sqrt(line[:,0]**2 + line[:,1]**2).reshape(-1,1)\n",
    "    line /= n\n",
    "    return line\n",
    "\n",
    "#Normalize the vector\n",
    "l_norm = normalize_vector(x.dot(F.T))\n",
    "for i, (j, row) in enumerate(x.iterrows()):\n",
    "    source_descriptor = e.source.descriptors[j]\n",
    "    epipolar_line = l_norm[i]    \n",
    "    dist = np.abs(epipolar_line.dot(x1.T))\n",
    "    candidates = dist.argsort()\n",
    "    dists = dist[candidates]\n",
    "    # Plot the base\n",
    "    show_base(e)\n",
    "    plot(row['x'], row['y'], 'ro')\n",
    "    flag_distance = math.inf\n",
    "    match = None\n",
    "    for k in dists[dists < threshold]:\n",
    "        didx = x1[candidates[k]]\n",
    "        print(didx)\n",
    "        destination_descriptor = e.destination.descriptors[candidates[k]]\n",
    "\n",
    "        destination_descriptor = e.destination.descriptors[candidates[k]]\n",
    "        descriptor_distance = cv2.norm(source_descriptor, destination_descriptor, cv2.NORM_L2)\n",
    "        plot(didx[0]+ 100 + 1012, didx[1], 'bo')\n",
    "        if descriptor_distance < flag_distance:\n",
    "            flag_distance = descriptor_distance\n",
    "            match = didx\n",
    "    try:\n",
    "        plot(match[0] + 100 + 1012, match[1], 'ro')\n",
    "    except:pass\n",
    "    show()\n",
    "    if i == 10:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As above, except, try rto use the fundamental matrix from edge `[0][2]` to increase depth on `[0][1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "THRESHOLD = 4\n",
    "\n",
    "e = cg[0][2]\n",
    "F = e.fundamental_matrix\n",
    "match_idx = e.matches[e.fundamental_matrix.mask]\n",
    "\n",
    "x = e.source.get_keypoint_coordinates(index=match_idx['source_idx'], homogeneous=True)\n",
    "x1 = e.destination.get_keypoint_coordinates(index=match_idx['destination_idx'], homogeneous=True)\n",
    "\n",
    "#Normalize the vector\n",
    "l_norms = normalize_vector(x.dot(F.T))\n",
    "\n",
    "F_error = np.abs(np.sum(l_norms * x1, axis=1))\n",
    "print(F_error.describe())\n",
    "#print(dists)\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from eberly http://www.geometrictools.com/Documentation/MinimalCycleBasis.pdf\n",
    "coords = {}\n",
    "coords[0] = 1,8\n",
    "coords[1] = 1,7\n",
    "coords[2] = 4,7\n",
    "coords[3] = 0,4\n",
    "coords[4] = 5,4\n",
    "coords[5] = 3,5\n",
    "coords[6] = 2, 4.5\n",
    "coords[7] = 6.5, 9\n",
    "coords[8] = 6.2, 5\n",
    "coords[9] = 5.5,3\n",
    "coords[10] = 7,3\n",
    "coords[11] = 7.5, 7.25\n",
    "coords[12] = 8,4\n",
    "coords[13] = 11.5, 7.25\n",
    "coords[14] = 9, 1\n",
    "coords[15] = 11, 3\n",
    "coords[16] = 12, 2\n",
    "coords[17] = 12, 5\n",
    "coords[18] = 13.5, 6\n",
    "coords[19] = 14, 7.25\n",
    "coords[20] = 16, 4\n",
    "coords[21] = 18, 8.5\n",
    "coords[22] = 16, 1\n",
    "coords[23] = 21, 1\n",
    "coords[24] = 21, 4\n",
    "coords[25] = 18, 3.5\n",
    "coords[26] = 17, 2\n",
    "coords[27] = 19, 2\n",
    "\n",
    "\n",
    "vertices = {}\n",
    "for v in range(28):\n",
    "    vertices[v] = []\n",
    "    \n",
    "vertices[1] = [2,3]\n",
    "vertices[2] = [1,4,7]\n",
    "vertices[3] = [1,4]\n",
    "vertices[4] = [2,3,5]\n",
    "vertices[5] = [4,6]\n",
    "vertices[6] = [5]\n",
    "vertices[7] = [2,11]\n",
    "vertices[8] = [9,10]\n",
    "vertices[9] = [8,10]\n",
    "vertices[10] = [8,9]\n",
    "vertices[11] = [7,12,13]\n",
    "vertices[12] = [11,13,20]\n",
    "vertices[13] = [11,12,18]\n",
    "vertices[14] = [15]\n",
    "vertices[15] = [14, 16]\n",
    "vertices[16] = [15]\n",
    "vertices[18] = [13,19]\n",
    "vertices[19] = [18,20,21]\n",
    "vertices[20] = [12,19,21,22,24]\n",
    "vertices[21] = [19,20]\n",
    "vertices[22] = [20,23]\n",
    "vertices[23] = [22,24]\n",
    "vertices[24] = [20,23]\n",
    "vertices[25] = [26,27]\n",
    "vertices[26] = [25,27]\n",
    "vertices[27] = [25,26]\n",
    "\n",
    "eberly = vertices.copy()\n",
    "\n",
    "eg = nx.Graph(vertices)\n",
    "g = nx.Graph(vertices)\n",
    "nx.draw(g, coords, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print([i for i in nx.cycle_basis(g) if len(i) == 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = nx.Graph()\n",
    "g.add_edges_from([(0,1), (0,2), (1,2), (0,3), (1,3), (2,3)])\n",
    "nx.draw(g, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx.find_cycle(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import leastsq\n",
    "\n",
    "e = cg[0][1]\n",
    "H = e.homography\n",
    "print(H)\n",
    "\n",
    "s_pts = e.source.get_keypoint_coordinates(index=e.matches['source_idx'], homogeneous=True).values\n",
    "d_pts = e.destination.get_keypoint_coordinates(index=e.matches['destination_idx'], homogeneous=True).values\n",
    "\n",
    "#Cost Function\n",
    "def f(H, ):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cg[1][2].plot(clean_keys=['ransac'], line_kwargs={'linewidth':0})\n",
    "show()\n",
    "cg[0][1].plot(clean_keys=['ransac'], line_kwargs={'linewidth':0})\n",
    "show()\n",
    "cg[0][2].plot(clean_keys=['ransac'], line_kwargs={'linewidth':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Refinement should not look at the point to line distance, but at the error in the theoretical best, 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = cg[0][1]\n",
    "F = e.fundamental_matrix\n",
    "\n",
    "f_matches = e.matches[F.mask]\n",
    "sc = e.source.get_keypoints().loc[f_matches['source_idx']][['x', 'y']]\n",
    "dc = e.destination.get_keypoints().loc[f_matches['destination_idx']][['x', 'y']]\n",
    "all_dc = e.destination.get_keypoints()[['x', 'y']]\n",
    "\n",
    "sc_h = np.ones((len(sc), 3))\n",
    "sc_h[:,:2] = sc\n",
    "\n",
    "dc_h = np.ones((len(dc), 3))\n",
    "dc_h[:,:2] = dc\n",
    "\n",
    "for j, (i, m) in enumerate(f_matches.iterrows()):\n",
    "    print(sc_h[j].T.dot(F).dot(dc_h[j]))\n",
    "    print(m['source_idx'])\n",
    "\n",
    "v = np.empty(len(dc_h))\n",
    "for i, r in enumerate(dc_h):\n",
    "    v[i] = sc_h[0].T.dot(F).dot(r)\n",
    "print(sc)\n",
    "print(min(abs(v)), np.argmin(abs(v)))\n",
    "print(sc.iloc[0], dc.iloc[120])\n",
    "print(f_matches[f_matches['source_idx'] == 265])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cg.to_cnet(clean_keys=['suppress'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The graph object:\n",
    "The underlying data structure is a graph, where each node is an image and each edge is the connectivity between nodes.  Nodes and Edges are classes with associated attributes and methods.  This notebook primarily focuses on the plotting functionality on the graph (and graph components).\n",
    "\n",
    "In these notebooks, the graph object is being stored in the variable `cg`.  Access to nodes and edges is positional.\n",
    "\n",
    "  * To access a node in the graph:  `cg[node_idx]`, e.g. `cg[0]`.\n",
    "  * To access an edge in the graph: `cg[source_idx][destination_idx]`, e.g. `cg[0][1]`\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cg.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot features at an individual node, e.g. a single image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All defaults are used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cg.node[1].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example specifies a plotting layout, passing in an axis object and passes along a color.  All the MatPlotLib plotting arguments are supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax1 = plt.subplot(1,1,1)\n",
    "ax = cg.node[0].plot(ax=ax1, color='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Matches on an Edge\n",
    "The plotting capability on a given node is limited to a single image; one can envision the node as being the image with all associated metadata and derived information.  The edge represents the overlap between images and resultant shared information, e.g. point correspondences, a homography, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the matches between an edge using two outlier detector masks\n",
    "To get a rough idea of what a 'good' results should be, we should see no, or few, lines which intersect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "ax = cg.edge[0][1].plot(clean_keys=['ratio', 'symmetry', 'fundamental'], ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now plot with the added, ransac computed mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cg.edge[0][1].plot(clean_keys=['ratio', 'symmetry', 'fundamental'], line_kwargs={'linewidth':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Coverage Metric\n",
    "We compute a coverage metric by utilizing the homography to project the destination image corner pixel coordinates into the source image and computing the intersection.  This is a rough estimate that is as good (or poor) as the homography."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "H = cg.edge[0][1].homography\n",
    "print('Not zero is good:', H.determinant)\n",
    "print('Not huge is good: ', H.condition)\n",
    "print('Shifts less than one pixel in all directions are good:', H.rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Ideal coverage would be 1.0\n",
    "cg.edge[0][1].coverage_ratio(clean_keys=['ransac'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above suggests that the quality is a function of the homography.  Just how good is the homography?  We can use the determinant (something near 1 is bad), the condition (a very large number, e.g. $10^15$ is bad), or the RMSE (reported in the x and y directions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing Keypoint Information\n",
    "Here we want to explore the attributes of the keypoints, using the masking information, e.g. the outlier detection methods.  The question is, what are the characteristics of those keypoints that have made it through the outlier detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skp, dkp = cg.edge[0][1].keypoints(clean_keys=['ratio', 'symmetry', 'ransac'])\n",
    "display(skp)\n",
    "display(dkp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subpixel Register\n",
    "We suggest only subpixel registering 'good' candidate matches as the subpixel registration process can be time consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cg.edge[0][1].subpixel_register(clean_keys=['fundamental', 'symmetry', 'ratio'],template_size=5, search_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cg.edge[0][1].plot(clean_keys=['ratio', 'symmetry', 'fundamental', 'subpixel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cg.edge[0][1].plot(clean_keys=['ratio', 'symmetry', 'fundamental', 'subpixel'], line_kwargs={'linewidth':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Suppression vis Disk Covering\n",
    "This method seeks to keep the $k$ strongest correlations with a good spatial distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cg.edge[0][1].suppress(k=100)\n",
    "\n",
    "# Plot, in blue the points that passed all outlier detectors so far\n",
    "cg.edge[0][1].plot(clean_keys=['ratio', 'symmetry', 'fundamental', 'subpixel'], line_kwargs={'linewidth':0})\n",
    "# Overlay, in red, the points that remain after suppression\n",
    "cg.edge[0][1].plot(clean_keys=['suppression'], line_kwargs={'linewidth':0}, scatter_kwargs={'color':'red'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$x^{\\intercal}Fx = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$d = \\frac{\\lvert ax_{0} + by_{0} + c \\rvert}{\\sqrt{a^{2} + b^{2}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
